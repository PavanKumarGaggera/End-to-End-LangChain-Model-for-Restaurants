# -*- coding: utf-8 -*-
"""AI_Agent_For_Restuarants.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1rNxjPGvG2Oal8-r1QykCMW7e-OivxSLj

# End-to-End-LangChain Model for restaurants

## Importing All Necessary Libraries
"""

import os
from langchain_community.document_loaders import WebBaseLoader
from langchain.text_splitter import CharacterTextSplitter
from langchain.embeddings import HuggingFaceEmbeddings
from langchain.vectorstores import FAISS
from langchain.chains import ConversationalRetrievalChain
from langchain.memory import ConversationBufferMemory
from langchain.chat_models import ChatOpenAI
import openai

os.environ["OPENAI_API_KEY"] ="Your_API_KEY"

openai_api_key = os.getenv("OPENAI_API_KEY")

url = "https://order.toasttab.com/online/ellys-brunch-and-cafe-norridge-5050-n-cumberland-ave"

loader = WebBaseLoader(url)

raw_docs = loader.load()

text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)
documents = text_splitter.split_documents(raw_docs)

embeddings = HuggingFaceEmbeddings(model_name="sentence-transformers/all-MiniLM-L6-v2")

vectorstore = FAISS.from_documents(documents, embeddings)

memory = ConversationBufferMemory(memory_key="chat_history", return_messages=True)

qa = ConversationalRetrievalChain.from_llm(ChatOpenAI(openai_api_key = openai_api_key,
                                                      model = "gpt-4o",
                                                      temperature=0),
                                           vectorstore.as_retriever(),
                                           memory=memory)

query = "Can you recommend a meal that is both spicy and nut-free?"

result = qa({'question':query})

result["answer"]

